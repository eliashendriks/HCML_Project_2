{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMSxpJAkqYzk"
   },
   "source": [
    "# Programming Assignment II: Explainability\n",
    "\n",
    "In this assignment you will train machine learning models and experiment with techniques discussed in the lectures.\n",
    "This assignment makes use of existing Python libraries for some questions. We have provided links to tutorials/examples if you're not familiar with them yet.\n",
    "\n",
    "All code that you implement should be in this notebook. You should submit:\n",
    "* This notebook with your code added. Make sure to add enough documentation. Also provide complete answers to the more theoretical questions in this notebook. These questions are followed by an 'answer indent':\n",
    "> Answer:\n",
    "\n",
    "The notebook .ipynb should have the name format `Prog_Explainability_Group_X.ipynb`, where X is your programming group ID.\n",
    "\n",
    "Important notes:\n",
    "* Deadline for this assignment is **Friday, May 30, 17:00**.\n",
    "* Send it to both Maria Muratidi (m.mouratidi@uu.nl) and Heysem Kaya (h.kaya@uu.nl), CCing your programming partner.\n",
    "* Title of the email: [INFOMHCML] Explainability programming assignment submission [X], with X the number of your group.\n",
    "* There will be a lab session to assist you with the assignment on **Tuesday, May 27, between 11:00-12:45 at DALTON 500 - 6.27 and DALTON 500 - 8.27**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyaViIx8WzS"
   },
   "source": [
    "### Installation\n",
    "\n",
    "For this assignment, we are going to use the following Python packages:\n",
    "graphviz, matplotlib, pandas, statsmodels, openpyxl, interpret, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6EaC6P7RqXOh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\jjant\\anaconda4\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jjant\\anaconda4\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jjant\\anaconda4\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\jjant\\anaconda4\\lib\\site-packages (0.13.5)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\jjant\\anaconda4\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from statsmodels) (1.10.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Collecting interpret\n",
      "  Downloading interpret-0.6.10-py3-none-any.whl (1.4 kB)\n",
      "Collecting interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10\n",
      "  Downloading interpret_core-0.6.10-py3-none-any.whl (16.6 MB)\n",
      "     ---------------------------------------- 16.6/16.6 MB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=0.19.2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.1.1)\n",
      "Requirement already satisfied: plotly>=3.8.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.22.0)\n",
      "Requirement already satisfied: psutil>=5.6.2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.9.0)\n",
      "Requirement already satisfied: dill>=0.2.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.3.6)\n",
      "Collecting shap>=0.28.5\n",
      "  Downloading shap-0.47.2-cp310-cp310-win_amd64.whl (544 kB)\n",
      "     -------------------------------------- 544.2/544.2 kB 8.6 MB/s eta 0:00:00\n",
      "Collecting SALib>=1.3.3\n",
      "  Downloading salib-1.5.1-py3-none-any.whl (778 kB)\n",
      "     -------------------------------------- 778.9/778.9 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting dash-core-components>=1.0.0\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-cytoscape>=0.1.1\n",
      "  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n",
      "     ---------------------------------------- 4.0/4.0 MB 9.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dash-html-components>=1.0.0\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.28.1)\n",
      "Collecting dash<3.0.0,>=1.0.0\n",
      "  Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 6.8 MB/s eta 0:00:00\n",
      "Collecting dash-table>=4.1.0\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Collecting gevent>=1.3.6\n",
      "  Downloading gevent-25.5.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 8.1 MB/s eta 0:00:00\n",
      "Collecting aplr>=10.6.1\n",
      "  Downloading aplr-10.9.0-cp310-cp310-win_amd64.whl (259 kB)\n",
      "     -------------------------------------- 259.8/259.8 kB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipykernel>=4.10.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (6.19.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (8.10.0)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.11.3)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (65.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.4.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.4.0)\n",
      "Collecting greenlet>=3.2.2\n",
      "  Downloading greenlet-3.2.2-cp310-cp310-win_amd64.whl (294 kB)\n",
      "     -------------------------------------- 295.0/295.0 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting cffi>=1.17.1\n",
      "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (6.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.1.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (7.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (22.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.1.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (23.2.0)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.7.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.4.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.18.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from pandas>=0.19.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from pandas>=0.19.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from pandas>=0.19.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (8.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.0.4)\n",
      "Requirement already satisfied: matplotlib>=3.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.7.0)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.10.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "     -------------------------------------- 134.9/134.9 kB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from scikit-learn>=0.18.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.64.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.0.0)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.56.4)\n",
      "Collecting slicer==0.0.8\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from cffi>=1.17.1->gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.21)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (8.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.2.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (9.4.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from numba>=0.54->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.39.1)\n",
      "Collecting numba>=0.54\n",
      "  Downloading numba-0.61.2-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "     ---------------------------------------- 2.8/2.8 MB 8.2 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-win_amd64.whl (30.3 MB)\n",
      "     ---------------------------------------- 30.3/30.3 MB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from Werkzeug<3.1->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from importlib-metadata->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.11.0)\n",
      "Collecting dill>=0.2.5\n",
      "  Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "     -------------------------------------- 119.7/119.7 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: executing in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.0.5)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (305.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.5.2)\n",
      "Building wheels for collected packages: dash-cytoscape\n",
      "  Building wheel for dash-cytoscape (setup.py): started\n",
      "  Building wheel for dash-cytoscape (setup.py): finished with status 'done'\n",
      "  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010751 sha256=d527977691a29d4e5f3b72ebcdc1f2c0920e84986889dae5265636ede04c6c20\n",
      "  Stored in directory: c:\\users\\jjant\\appdata\\local\\pip\\cache\\wheels\\39\\bb\\5b\\8ca2b8a4260fa981a354b1cd0524a5cd6be3f2fc49479cf69f\n",
      "Successfully built dash-cytoscape\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, zope.event, slicer, retrying, llvmlite, greenlet, dill, cffi, aplr, numba, multiprocess, gevent, shap, SALib, interpret-core, dash, dash-cytoscape, interpret\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.39.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\jjant\\anaconda4\\lib\\site-packages (1.2.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "     -------------------------------------- 307.7/307.7 kB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jjant\\anaconda4\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Installing packages\n",
    "!pip install graphviz\n",
    "!pip install matplotlib pandas statsmodels openpyxl\n",
    "!pip install interpret\n",
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSC0_WEpY0k"
   },
   "source": [
    "### Read the data\n",
    "We are going to use the ChaLearn LAP-FI (First Impressions) Dataset. This dataset contains 10.000 data points, which correspond to videos collected from YouTube and annotated via Amazon Mechanical Turk for the BIG-5 personality impressions: openness, extraversion, conscientiousness, neuroticism, agreeableness.\n",
    "\n",
    "These five personality impression scores will be used as features to predict the outcome variable: a job interview invitation.\n",
    "\n",
    "For a detailed description, see the [paper of the dataset](https://ieeexplore.ieee.org/abstract/document/7966041?casa_token=1Y03H5ykCqsAAAAA:VLhCcjAgByJ2hTdKhulmIUiXIVepEJfFyB7HM0XVts7bN8Gi8wMsiTT0qZ--I_kq8wiUHIpPN7es).\n",
    "\n",
    "\n",
    "1.   If you use Google Colab, upload 'all_df.csv' (you can find this file on blackboard) through the upload button in the Files tab.\n",
    "  - Copy the path of the file;\n",
    "  - Run the cell below with your path. This will ask you for permission to access your Google Drive files and then you can access the data.\n",
    "2.   If you are running this notebook at your own machine (jupyter notebook), locate the 'all_df.csv' file in the same folder this notebook exists. Then you can run the second cell below.\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okPuwNvww9F-"
   },
   "outputs": [],
   "source": [
    "# Run this cell only if you use Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Make sure you uploaded all_df.csv to your Google Drive and change the path\n",
    "# to the directory it is located in (usually in content/gdrive/MyDrive/...)\n",
    "%cd  '/content/gdrive/MyDrive/HCML/Explainability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fleSmPrE7UMT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Run this cell (both when working locally or with Google Colab)\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"all_df.csv\")\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQpW5C3Sg9YA"
   },
   "source": [
    "### Loading and preprocessing the data\n",
    "There are 6000, 2000 and 2000 examples for training, validation/development and test set respectively. In the data this is indicated by the feature `split`.\n",
    "\n",
    "The training set is used to train models, the validation/development set to optimize the models hyper-parameters, and the test set to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JycjPmn_7p41"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# global variables\n",
    "FEATURE_NAMES = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
    "LABEL_NAME = 'interview'\n",
    "\n",
    "def load_data():\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set[FEATURE_NAMES]\n",
    "        labels = data_set[LABEL_NAME]\n",
    "        return features, labels\n",
    "\n",
    "    train_set = data[data['split'] == 'training']\n",
    "    val_set = data[data['split'] == 'validation']\n",
    "    test_set = data[data['split'] == 'test']\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    val_features, val_labels = split_feature_label(val_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, val_features, \\\n",
    "        val_labels, test_features, test_labels\n",
    "\n",
    "# Load the data with the function above\n",
    "(train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbkcGeJT6stA"
   },
   "source": [
    "# Part 1. Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QabF2JOdMTI4"
   },
   "source": [
    "### **1. Linear Regression**\n",
    "\n",
    "Train a linear regression model (we recommend the `statsmodels.api` package with the ordinary least squares model `sm`).\n",
    "\n",
    "Hint: to get a linear regression model, you should manually add a constant variable (usually called bias or intercept - that has a fixed value of 1 for all instances) to the data, either by adding it column yourself or by using the `add_constant()` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg6Tc7uD6jL_"
   },
   "source": [
    "**Q1.1**\n",
    "\n",
    "Provide the $R^2$ (goodness of fit) statistic and for each feature (+ the bias variable), the following in tabular format:\n",
    "* Weight estimate (coef)\n",
    "* SE (standard error of estimates)\n",
    "* T-statistic\n",
    "\n",
    "Hint: You can print the summary of the model using `.summary()` to do this. This gives an extensive overview of the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B91BszFhMStw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              interview   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.914\n",
      "Method:                 Least Squares   F-statistic:                 1.278e+04\n",
      "Date:                Sun, 25 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:33:46   Log-Likelihood:                 10232.\n",
      "No. Observations:                6000   AIC:                        -2.045e+04\n",
      "Df Residuals:                    5994   BIC:                        -2.041e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                -0.0727      0.003    -28.052      0.000      -0.078      -0.068\n",
      "extraversion          0.1891      0.007     26.954      0.000       0.175       0.203\n",
      "neuroticism           0.2397      0.008     31.013      0.000       0.225       0.255\n",
      "agreeableness         0.2573      0.007     38.337      0.000       0.244       0.270\n",
      "conscientiousness     0.3293      0.005     59.926      0.000       0.318       0.340\n",
      "openness              0.0857      0.007     12.753      0.000       0.073       0.099\n",
      "==============================================================================\n",
      "Omnibus:                        7.437   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.024   Jarque-Bera (JB):                7.444\n",
      "Skew:                          -0.086   Prob(JB):                       0.0242\n",
      "Kurtosis:                       3.000   Cond. No.                         24.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# We recommend the statsmodels package\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Your code to add a bias/intercept variable\n",
    "train_features_with_bias = sm.add_constant(train_features)\n",
    "\n",
    "# Train the model and print out the summary\n",
    "mod = sm.OLS(train_labels, train_features_with_bias)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQSPWuVzNBmX"
   },
   "source": [
    "**Q1.2**\n",
    "\n",
    "Which three features are the most important?\n",
    "\n",
    "> Answer:\n",
    "- Conscientiousness\n",
    "- Agreeableness\n",
    "- Neuroticism\n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6miEyz_f66Ei"
   },
   "source": [
    "**Q1.3**\n",
    "\n",
    "How does the predicted 'interview' score change with an 0.1 increase of the 'conscientiousness' feature given that all other feature values remain the same?\n",
    "\n",
    "> Answer:\n",
    "Consider that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AlVsA0ZhWbw"
   },
   "source": [
    "**Q1.4**\n",
    "\n",
    "Show bar graph illustrations of the feature effects for the first two validation set instances.\n",
    "\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abB-9YswhkMo"
   },
   "outputs": [],
   "source": [
    "# Compute the Feature Effects\n",
    "\n",
    "# Show bar graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tj6Pri4HBeO"
   },
   "source": [
    "**Q1.5**\n",
    "\n",
    "Reflection: why would training a regression tree not work well for this dataset in terms of model interpretability? And under what conditions could the dataset be used with a decision tree to yield an interpretable model?\n",
    "\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7r09mMfeo2k"
   },
   "source": [
    "### **2. Explainable Boosting Model**\n",
    "Train an Explainable Boosting Machine (EBM) with [InterpretML](https://interpret.ml/docs/ebm.html). EBM is a Generalized Additive Model (GAM) that is highly intelligible and explainable.\n",
    "\n",
    "The `interpret` package provides both global and local explanation functions: `explain_global()` and `explain_local()` can be used to interpret a ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUxfqAHb7ZgX"
   },
   "source": [
    "**Q2.1**\n",
    "\n",
    "Visualize/provide global (model-wise) feature importances for EBM as a table or figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbqYT0Wh34k-"
   },
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from interpret import show\n",
    "\n",
    "# EBM Global feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cJ1uiHf34_l"
   },
   "source": [
    "**Q2.2**\n",
    "\n",
    "What are the most important two features in EBM? Are they the same as in the linear model?\n",
    "\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUxRg7Xr7hr1"
   },
   "source": [
    "Now, to have an idea how EBM treats the input and generates the explanation, visualize EBM local explanations on a synthetic instance generated from training set mean feature vector as input and training set mean response as output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BieO0LiSceUd"
   },
   "outputs": [],
   "source": [
    "# EBM Local explanation for training set mean vector with corresponding training set mean label\n",
    "train_mean_x = pd.DataFrame(train_features.mean(axis=0)).T\n",
    "train_mean_y = pd.DataFrame([train_labels.mean()])\n",
    "\n",
    "print(train_mean_x)\n",
    "print(train_mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TMeydtDsB35"
   },
   "source": [
    "**Q2.3**\n",
    "\n",
    "Now, visualize local (instance-wise) feature importances for the first two instances of the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce00C36ilxxC"
   },
   "outputs": [],
   "source": [
    "# EBM local explanations for the first two development set instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTFmCfAn5xQK"
   },
   "source": [
    "**Q2.4**\n",
    "\n",
    "Let's compare these feature importances with the feature effects in question 1.4.\n",
    "\n",
    "* Are the feature contribution orderings the same in both models for the two instances?\n",
    "> Answer:\n",
    "\n",
    "* For the second example's explanation, why do you think the contribution of *conscientiousness* is positive, while the contribution of *agreeableness* is negative? (Hint: consider the feature values relative to the training set mean values you calculated / processed in the former subquestion.)\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7dAwTIfbsc"
   },
   "source": [
    "# Part 2. Model-Agnostic Methods for Interpreting/Explaining NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EbowFSZAZj6"
   },
   "source": [
    "### **3. Training Neural Networks**\n",
    "Train a one-layer Neural Network (multi-layer perceptron (MLP) Regressor, but with one layer) with the following settings:\n",
    "\n",
    "- Activation function: ReLU\n",
    "- Size of the hidden layer: 50 neurons\n",
    "- Recommended optimizer/solver: Adam\n",
    "\n",
    "For a tutorial see [Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "**Q3.1**\n",
    "\n",
    "Apply the trained neural network model to the development set to find the best hyperparameters (such as learning rate). Report the Root Mean Square Error (RMSE) performance measure.\n",
    "\n",
    "**Note.** A development set RMSE below 0.045 is reasonable, then you can apply the corresponding model on the test set in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQjg_qtCf_WD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Train the MLPRegressor and show RMSE on development set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQySPj5Nt_sO"
   },
   "source": [
    "**Q3.2**\n",
    "\n",
    "Now use the best settings to report the Root Mean Square Error (RMSE) performance measure on the test set.\n",
    "\n",
    "It is possible to use the combination of the training and development sets to retrain the model and report the test set performance. You can also use the model that was trained on the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxuJUUUnPgGb"
   },
   "outputs": [],
   "source": [
    "# RMSE on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huX2fiH1-Qir"
   },
   "source": [
    "Now we can analyze factors that influence the predictions. Both Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots can be used to visualize and analyze interaction between the target response and a set of input features of interest.\n",
    "\n",
    "See the [Documentation](https://scikit-learn.org/stable/modules/partial_dependence.html) on how to use PDPs and ICEs.\n",
    "\n",
    "**Q3.3**\n",
    "\n",
    "Generate univariate and bivariate PDPs for the `conscientiousness` and `agreeableness` features with the neural network you trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqVV2yHdpSdl"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# PDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M584ROYo1czo"
   },
   "source": [
    "**Q3.4**\n",
    "\n",
    "What do these plots show?\n",
    "\n",
    "> Answer:\n",
    "\n",
    "**Q3.5**\n",
    "\n",
    "Now generate ICE plots for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig_iwDVqQBdY"
   },
   "outputs": [],
   "source": [
    "# ICEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y75fIVlY2abm"
   },
   "source": [
    "**Q3.6**\n",
    "\n",
    "What can you conclude from ICE plots above?\n",
    "\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0NLZmwHv5tx"
   },
   "source": [
    "**Q3.7**\n",
    "\n",
    "Implement the PDF (Partial Dependence Function) for univariate analysis of the trained NN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyRSmdVD9LF8"
   },
   "outputs": [],
   "source": [
    "def PDF(X, model, feature):\n",
    "  \"\"\"\n",
    "  Input   Dataset 'X', Model 'model', feature_name 'feature'\n",
    "  Output  x_values: independent variable values\n",
    "          f_values: corresponding output per x value\n",
    "  \"\"\"\n",
    "  # Note: uncomment the lines below and complete the right hand side (where you see '..' to set them to suitable values, respective explanations are provided for each variable\n",
    "  # num_samples = ..  # set the number of samples/steps to slice the range of the continuous feature, e.g., 100.\n",
    "  # min_val = ..      # minimum value of the given feature\n",
    "  # max_val = ..      # maximum value of the given feature\n",
    "  # step_size = ..    # see the algorithm in corresponsing lecture slides to calculate the step size as a function of the above variables\n",
    "  # x_values = ..     # x_values at which we will calculate the partial function of the given feature\n",
    "  # f_values = ..     # the calculated partial function values corresponding to x_values\n",
    "\n",
    "  # for k in range(num_samples - 1):\n",
    "    # Change part of the data according to the formula of PDF algorithm\n",
    "    # Let the model predict and calculate the f_value for this k\n",
    "\n",
    "  # return x_values, f_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-erhkuKc9Lbb"
   },
   "source": [
    "**Q3.8**\n",
    "\n",
    "Calculate and visualize the feature importances obtained by your PDF algorithm with a bar graph. How do we calculate the feature importance given the x_values and y_values of the PDF algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGZc06rb-ksR"
   },
   "outputs": [],
   "source": [
    "# First calculate the x_values and f_values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwjNZFql9QtZ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Fit a linear model per feature, what is the output of this linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I5Z1dRl86BP"
   },
   "source": [
    "**Q3.9**\n",
    "\n",
    "What are the two most important features obtained by the PDF algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
    "\n",
    "> Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8slEz838w8_"
   },
   "source": [
    "### **4. Permutation Feature Importance**\n",
    "\n",
    "**Q4.1**\n",
    "\n",
    "Implement the permutation feature importance algorithm using RMSE as the error function. No existing libraries (barring the RMSE from `sklearn` and a function for random sampling / permutation) are allowed to be used, you will implement it yourself with the framework below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7xUqEYnv4wA"
   },
   "outputs": [],
   "source": [
    "def PFI(X, labels, model, base_rmse):\n",
    "  results = []\n",
    "\n",
    "  for feature in X:\n",
    "    # Create a copy of X_test\n",
    "    # Scramble the values of the given predictor\n",
    "    # Calculate the new RMSE\n",
    "    # Append the increase in MSE to the list of results\n",
    "\n",
    "  # Put the results into a pandas dataframe and rank the predictors by score\n",
    "\n",
    "  # return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHemT4b73rwY"
   },
   "source": [
    "**Q4.2**\n",
    "\n",
    "Visualize the feature importances obtained by your PFI algorithm with a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxZ9pPBoVsdi"
   },
   "outputs": [],
   "source": [
    "# Bar graph of feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmvAN-wT336H"
   },
   "source": [
    "**Q4.3**\n",
    "\n",
    "What are the two most important features obtained by the permutation feature importance algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
    "\n",
    "> Answer:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
